{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib Decision Trees to Predict Network Attacks\n",
    "### Classifier will predict `normal` or `attack`.  \n",
    "\n",
    "Source: https://github.com/jadianes/spark-py-notebooks/blob/master/nb9-mllib-trees/nb9-mllib-trees.ipynb  \n",
    "File Last Updated: Feb 16, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Provided in the KDD Cup 1999, the file is provided as a Gzip file that we will download locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", \"kddcup.data.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "./kddcup.data.gz MapPartitionsRDD[16] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = \"./kddcup.data.gz\"\n",
    "raw_data = sc.textFile(data_file)\n",
    "raw_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in dataset: 4898431\n"
     ]
    }
   ],
   "source": [
    "print(\"Records in dataset: {}\".format(raw_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0,tcp,http,SF,215,45076,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,0,0,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,tcp,http,SF,162,4528,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,2,2,0.00,0.00,0.00,0.00,1.00,0.00,0.00,1,1,1.00,0.00,1.00,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,tcp,http,SF,236,1228,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,2,2,1.00,0.00,0.50,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [KDD Cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) also provide test data that we will load in a separate RDD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft = urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", \"corrected.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_file = \"./corrected.gz\"\n",
    "test_raw_data = sc.textFile(test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size is 311029\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data size is {}\".format(test_raw_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0,udp,private,SF,105,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,254,1.00,0.01,0.00,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,udp,private,SF,105,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,254,1.00,0.01,0.00,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,udp,private,SF,105,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,254,1.00,0.01,0.00,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For categorical variables, we need to convert them to numerical factors. But first we need to obtain all the possible levels. \n",
    "We will use *set* transformations on a csv parsed RDD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
    "test_csv_data = test_raw_data.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protocols = csv_data.map(lambda x: x[1]).distinct().collect()\n",
    "services = csv_data.map(lambda x: x[2]).distinct().collect()\n",
    "flags = csv_data.map(lambda x: x[3]).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'udp', u'icmp', u'tcp']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.index(u'udp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'urp_i', u'http_443', u'Z39_50', u'smtp', u'domain']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_labeled_point(line_split):\n",
    "    # leave_out = [41]\n",
    "    clean_line_split = line_split[0:41]\n",
    "    \n",
    "    # convert protocol to numeric categorical variable\n",
    "    try: \n",
    "        clean_line_split[1] = protocols.index(clean_line_split[1])\n",
    "    except:\n",
    "        clean_line_split[1] = len(protocols)\n",
    "        \n",
    "    # convert service to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[2] = services.index(clean_line_split[2])\n",
    "    except:\n",
    "        clean_line_split[2] = len(services)\n",
    "    \n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[3] = flags.index(clean_line_split[3])\n",
    "    except:\n",
    "        clean_line_split[3] = len(flags)\n",
    "    \n",
    "    # convert label to binary label\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "        \n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = csv_data.map(create_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,2.0,58.0,10.0,215.0,45076.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,2.0,58.0,10.0,162.0,4528.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,2.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_csv_data.map(create_labeled_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the decision tree classifier\n",
    "**(Took 193 seconds w default config)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier training time (secs): 193.72\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from time import time\n",
    "\n",
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model = DecisionTree.trainClassifier(training_data, \n",
    "                                          numClasses=2, \n",
    "                                          categoricalFeaturesInfo={1: len(protocols), 2: len(services), 3: len(flags)},\n",
    "                                          impurity='gini', \n",
    "                                          maxDepth=4, \n",
    "                                          maxBins=100)\n",
    "\n",
    "print(\"Classifier training time (secs): {}\".format(round(time() - t0, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the classification error on our test data, we use `map` on the `test_data` RDD and the model to predict each test point class.  \n",
    "\n",
    "Let's look at some labels and feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.map(lambda p: p.label).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([0.0, 0.0, 5.0, 10.0, 105.0, 146.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 255.0, 254.0, 1.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " DenseVector([0.0, 0.0, 5.0, 10.0, 105.0, 146.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 255.0, 254.0, 1.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.map(lambda p: p.features).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions at each test point\n",
    "predictions = tree_model.predict(test_data.map(lambda p: p.features))\n",
    "\n",
    "# zip labels and predictions\n",
    "labels_and_preds = test_data.map(lambda p: p.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 0.0)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_and_preds.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute classifier accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9183\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = labels_and_preds.filter(lambda (lab, pred): lab == pred).count() / float(test_data.count())\n",
    "\n",
    "print(\"Test accuracy = {}\".format(round(accuracy_test, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 4 with 27 nodes\n",
      "  If (feature 22 <= 33.0)\n",
      "   If (feature 25 <= 0.5)\n",
      "    If (feature 36 <= 0.48)\n",
      "     If (feature 34 <= 0.91)\n",
      "      Predict: 0.0\n",
      "     Else (feature 34 > 0.91)\n",
      "      Predict: 1.0\n",
      "    Else (feature 36 > 0.48)\n",
      "     If (feature 2 in {0.0,42.0,24.0,20.0,46.0,57.0,60.0,44.0,27.0,12.0,7.0,3.0,18.0,67.0,43.0,26.0,55.0,58.0,36.0,4.0,47.0,15.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {0.0,42.0,24.0,20.0,46.0,57.0,60.0,44.0,27.0,12.0,7.0,3.0,18.0,67.0,43.0,26.0,55.0,58.0,36.0,4.0,47.0,15.0})\n",
      "      Predict: 1.0\n",
      "   Else (feature 25 > 0.5)\n",
      "    If (feature 3 in {10.0,6.0,2.0,7.0,3.0,4.0})\n",
      "     If (feature 2 in {42.0,27.0,12.0,7.0,3.0,18.0,50.0,67.0,8.0,58.0,51.0,15.0,68.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {42.0,27.0,12.0,7.0,3.0,18.0,50.0,67.0,8.0,58.0,51.0,15.0,68.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 3 not in {10.0,6.0,2.0,7.0,3.0,4.0})\n",
      "     If (feature 38 <= 0.07)\n",
      "      Predict: 0.0\n",
      "     Else (feature 38 > 0.07)\n",
      "      Predict: 1.0\n",
      "  Else (feature 22 > 33.0)\n",
      "   If (feature 5 <= 0.0)\n",
      "    If (feature 2 in {0.0,52.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 2 not in {0.0,52.0})\n",
      "     If (feature 11 <= 0.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 11 > 0.0)\n",
      "      Predict: 0.0\n",
      "   Else (feature 5 > 0.0)\n",
      "    If (feature 29 <= 0.08)\n",
      "     If (feature 2 in {3.0,26.0,58.0,36.0,4.0,68.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {3.0,26.0,58.0,36.0,4.0,68.0})\n",
      "      Predict: 0.0\n",
      "    Else (feature 29 > 0.08)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a network interaction with the following features (see description here) will be classified as an attack by our model:\n",
    "\n",
    "* count, the number of connections to the same host as the current connection in the past two seconds, being greater than 32.  \n",
    "* dst_bytes, the number of data bytes from destination to source, is 0.  \n",
    "* service is neither level 0 nor 52.  \n",
    "* logged_in is false.\n",
    "\n",
    "From our services list we know that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service 0 is urp_i\n",
      "Service 52 is tftp_u\n"
     ]
    }
   ],
   "source": [
    "print \"Service 0 is {}\".format(services[0])\n",
    "print \"Service 52 is {}\".format(services[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can characterise network interactions with more than 32 connections to the same server in the last 2 seconds, transferring zero bytes from destination to source, where service is neither *urp_i* nor *tftp_u*, and not logged in, as network attacks. A similar approach can be used for each tree terminal node.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `count` is the first node split in the tree. Remember that each partition is chosen greedily by selecting the best split from a set of possible splits, in order to maximize the information gain at a tree node (see more [here](https://spark.apache.org/docs/latest/mllib-decision-tree.html#basic-algorithm)). At a second level we find variables `flag` (normal or error status of the connection) and `dst_bytes` (the number of data bytes from destination to source) and so on.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explaining capability of a classification (or regression) tree is one of its main benefits. Understanding data is a key factor to build better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a minimal model using the three main splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we know the main features predicting a network attack, thanks to our classification tree splits, let's use them to build a minimal classification tree with just the main three variables: `count`, `dst_bytes`, and `flag`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the appropriate function to create labeled points.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_labeled_point_minimal(line_split):\n",
    "    # leave_out = [41]\n",
    "    clean_line_split = line_split[3:4] + line_split[5:6] + line_split[22:23]\n",
    "    \n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[0] = flags.index(clean_line_split[0])\n",
    "    except:\n",
    "        clean_line_split[0] = len(flags)\n",
    "    \n",
    "    # convert label to binary label\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "        \n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_minimal = csv_data.map(create_labeled_point_minimal)\n",
    "test_data_minimal = test_csv_data.map(create_labeled_point_minimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That we use to train the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 132.567 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model_minimal = DecisionTree.trainClassifier(training_data_minimal, numClasses=2, \n",
    "                                          categoricalFeaturesInfo={0: len(flags)},\n",
    "                                          impurity='gini', maxDepth=3, maxBins=32)\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Classifier trained in {} seconds\".format(round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict on the testing data and calculate accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_minimal = tree_model_minimal.predict(test_data_minimal.map(lambda p: p.features))\n",
    "labels_and_preds_minimal = test_data_minimal.map(lambda p: p.label).zip(predictions_minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9049\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_minimal = labels_and_preds_minimal.filter(lambda (lab, pred): lab == pred).count() / float(test_data.count())\n",
    "\n",
    "print(\"Test accuracy = {}\".format(round(accuracy_test_minimal, 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
