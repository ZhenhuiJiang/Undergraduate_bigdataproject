{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: Linear Regression Modeling of California Home Prices\n",
    "Last updated: Feb 4, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Instructions\n",
    "In this project, we will work with the California Home Price dataset.  We will train a regression model to predict median home prices.  \n",
    "\n",
    "First, we will go through this example.  Then you will make modifications and run the code, collecting results.\n",
    "\n",
    "Learning Objectives\n",
    "Students will gain additional expertise in the following:\n",
    "\n",
    "RDDs, DataFrames, data preprocessing, feature engineering, model training, model evalulation\n",
    "\n",
    "## Lab Exercises\n",
    "\n",
    "1) Go through all code and fill in the missing cells. This will prep data, train a model, predict, and evaluate model fit.  Compute and report the Mean Squared Error (MSE) in a table at the very bottom, where all MSE values should be summarized.  \n",
    "Show all work.\n",
    "\n",
    "2) Repeat (1) with at least one additional feature from the original set.  \n",
    "3) Repeat (1) with at least one engineered feature based on one or more variables from the original set.  \n",
    "4) Repeat (1) but do Lasso Regression instead of Linear Regression. hint: change the parameter: `\n",
    "\n",
    "\n",
    "### Data Source\n",
    "StatLib---Datasets Archive  \n",
    "http://lib.stat.cmu.edu/datasets/\n",
    "\n",
    "houses.zip\n",
    "These spatial data contain 20,640 observations on housing prices with 9 economic covariates. It appeared in Pace and Barry (1997), \"Sparse Spatial Autoregressions\", Statistics and Probability Letters. Submitted by Kelley Pace (kpace@unix1.sncc.lsu.edu). [9/Nov/99] (536 kbytes)\n",
    "\n",
    "\n",
    "\n",
    "Data Description\n",
    "This tutorial makes use of the California Housing data set. It appeared in a 1997 paper titled Sparse Spatial Autoregressions, written by Pace, R. Kelley and Ronald Barry and published in the Statistics and Probability Letters journal. The researchers built this data set by using the 1990 California census data.\n",
    "\n",
    "The data contains one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people). In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "These spatial data contain 20,640 observations on housing prices with 9 economic variables\n",
    "\n",
    "All the block groups with zero entries for the independent and dependent variables have been excluded from the data.\n",
    "\n",
    "The Median house value is the dependent variable and will be assigned the role of the target variable in your ML model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (completed offline)\n",
    "\n",
    "cadata_raw.txt contains a data description at the top, followed by data.\n",
    "\n",
    "1. Separated data from header  \n",
    "   cal_housing_data_raw.txt  contains only data  \n",
    "   cal_housing_header.txt contains only text\n",
    "2. Some values are in scientific notation.  \n",
    "   Spacing is inconsistent (first 6 fields separated by 2 spaces. Lat/long separated by 1 space)  \n",
    "   Ran the following in Python to format values\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = pd.read_csv('/home/ubuntu/projects/cal_housing_data_raw.txt', header=None, sep='  ')\n",
    "\n",
    "d.columns=['v1','v2','v3','v4','v5','v6','v7','v8']  \n",
    "d['latitude'] = d.v8.map(lambda l: l.split()[0])  \n",
    "d['longitude'] = d.v8.map(lambda l: l.split()[1])  \n",
    "d.latitude = d.latitude.map(lambda v: float(v))  \n",
    "d.longitude = d.longitude.map(lambda v: float(v))  \n",
    "d.to_csv('/home/ubuntu/projects/cal_housing_data_preproc.txt', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark modules\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read text file, which is comma-separated\n",
    "house = pd.read_csv('data/cal_housing_data_preproc_w_header.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>median_income</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452600.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358500.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352100.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341300.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342200.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   median_house_value  median_income  housing_median_age  total_rooms  \\\n",
       "0            452600.0         8.3252                41.0        880.0   \n",
       "1            358500.0         8.3014                21.0       7099.0   \n",
       "2            352100.0         7.2574                52.0       1467.0   \n",
       "3            341300.0         5.6431                52.0       1274.0   \n",
       "4            342200.0         3.8462                52.0       1627.0   \n",
       "\n",
       "   total_bedrooms  population  households  latitude  longitude  \n",
       "0           129.0       322.0       126.0     37.88    -122.23  \n",
       "1          1106.0      2401.0      1138.0     37.86    -122.22  \n",
       "2           190.0       496.0       177.0     37.85    -122.24  \n",
       "3           235.0       558.0       219.0     37.85    -122.25  \n",
       "4           280.0       565.0       259.0     37.85    -122.25  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to Spark dataframe\n",
    "df = sqlCtx.createDataFrame(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+------------------+-----------+--------------+----------+----------+--------+---------+\n",
      "|median_house_value|    median_income|housing_median_age|total_rooms|total_bedrooms|population|households|latitude|longitude|\n",
      "+------------------+-----------------+------------------+-----------+--------------+----------+----------+--------+---------+\n",
      "|          452600.0|           8.3252|              41.0|      880.0|         129.0|     322.0|     126.0|   37.88|  -122.23|\n",
      "|          358500.0|           8.3014|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|   37.86|  -122.22|\n",
      "|          352100.0|7.257399999999999|              52.0|     1467.0|         190.0|     496.0|     177.0|   37.85|  -122.24|\n",
      "|          341300.0|           5.6431|              52.0|     1274.0|         235.0|     558.0|     219.0|   37.85|  -122.25|\n",
      "|          342200.0|           3.8462|              52.0|     1627.0|         280.0|     565.0|     259.0|   37.85|  -122.25|\n",
      "+------------------+-----------------+------------------+-----------+--------------+----------+----------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|median_house_value|    median_income|\n",
      "+------------------+-----------------+\n",
      "|          452600.0|           8.3252|\n",
      "|          358500.0|           8.3014|\n",
      "|          352100.0|7.257399999999999|\n",
      "|          341300.0|           5.6431|\n",
      "|          342200.0|           3.8462|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['median_house_value','median_income']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+-----------------+\n",
      "|summary|        households|median_house_value|    median_income|   total_bedrooms|\n",
      "+-------+------------------+------------------+-----------------+-----------------+\n",
      "|  count|             20640|             20640|            20640|            20640|\n",
      "|   mean| 499.5396802325581|206855.81690891474|3.870671002906974|537.8980135658915|\n",
      "| stddev|382.32975283161073|115395.61587441366|1.899821717945268|421.2479059431317|\n",
      "|    min|               1.0|           14999.0|           0.4999|              1.0|\n",
      "|    max|            6082.0|          500001.0|          15.0001|           6445.0|\n",
      "+-------+------------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "df.select('households','median_house_value','median_income','total_bedrooms').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Preprocessing\n",
    "\n",
    "We want to do three more things before training a model:  \n",
    "\n",
    "1) Scale the response variable median_house_value, dividing by 100000 and saving into column median_house_value_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df.withColumn('median_house_value_final',df.median_house_value/100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Feature Engineering\n",
    "\n",
    "Add new feature:  rooms_per_household (hint: use *withColumn()* function)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+------------------+-----------+--------------+----------+----------+--------+---------+------------------------+-------------------+\n",
      "|median_house_value|median_income|housing_median_age|total_rooms|total_bedrooms|population|households|latitude|longitude|median_house_value_final|rooms_per_household|\n",
      "+------------------+-------------+------------------+-----------+--------------+----------+----------+--------+---------+------------------------+-------------------+\n",
      "|          452600.0|       8.3252|              41.0|      880.0|         129.0|     322.0|     126.0|   37.88|  -122.23|                   4.526|  6.984126984126984|\n",
      "|          358500.0|       8.3014|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|   37.86|  -122.22|                   3.585|  6.238137082601054|\n",
      "+------------------+-------------+------------------+-----------+--------------+----------+----------+--------+---------+------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3=df_2.withColumn('rooms_per_household',df.total_rooms/df.households)\n",
    "df_3.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Select and standardize features\n",
    "\n",
    "Re-order and select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df_3.select(\"median_house_value_final\", \n",
    "              \"total_bedrooms\", \n",
    "              \"population\", \n",
    "              \"households\", \n",
    "              \"median_income\", \n",
    "              \"rooms_per_household\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+----------+----------+-----------------+-------------------+\n",
      "|median_house_value_final|total_bedrooms|population|households|    median_income|rooms_per_household|\n",
      "+------------------------+--------------+----------+----------+-----------------+-------------------+\n",
      "|                   4.526|         129.0|     322.0|     126.0|           8.3252|  6.984126984126984|\n",
      "|                   3.585|        1106.0|    2401.0|    1138.0|           8.3014|  6.238137082601054|\n",
      "|                   3.521|         190.0|     496.0|     177.0|7.257399999999999|  8.288135593220339|\n",
      "+------------------------+--------------+----------+----------+-----------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to standardize the features, but not the response variable. We can do this by converting the DF to an RDD and\n",
    "applying map()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = dfs.rdd.map(lambda x: (x[0], DenseVector(x[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.526, DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841])),\n",
       " (3.585, DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381])),\n",
       " (3.521, DenseVector([190.0, 496.0, 177.0, 7.2574, 8.2881]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for modeling\n",
    "df2 = sqlCtx.createDataFrame(input_data, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|4.526|[129.0,322.0,126....|\n",
      "|3.585|[1106.0,2401.0,11...|\n",
      "|3.521|[190.0,496.0,177....|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841]), features_scaled=DenseVector([0.3062, 0.2843, 0.3296, 4.3821, 2.8228])),\n",
       " Row(label=3.585, features=DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381]), features_scaled=DenseVector([2.6255, 2.1202, 2.9765, 4.3696, 2.5213]))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the DataFrame to the scaler; this computes the mean, standard deviation of each feature\n",
    "scaler = standardScaler.fit(df2)\n",
    "\n",
    "# Transform the data in `df2` with the scaler\n",
    "scaled_df = scaler.transform(df2)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train 80%, test 20% sets, using `seed=314`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training,test=scaled_df.randomSplit([0.8,0.2],seed=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the logistic regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each datapoint in the test set, make a prediction (hint: apply `transform()` to the model).\n",
    "You will want the returned object to be a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark-1.6.1-bin-hadoop2.6/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    }
   ],
   "source": [
    "predicted=lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+------------------+\n",
      "|label|            features|     features_scaled|        prediction|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|0.269|[543.0,1423.0,482...|[1.28902717933820...|1.6043857976084994|\n",
      "|0.329|[386.0,436.0,213....|[0.91632502987945...|1.3133532831902404|\n",
      "|0.396|[296.0,1228.0,289...|[0.70267411617699...|1.2867595070730435|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe to an rdd. Then select only the `prediction` and `label` fields (hint: use map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predAndLab = predicted.rdd.map(lambda x: (x.prediction, x.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.6043857976084994, 0.269),\n",
       " (1.3133532831902404, 0.329),\n",
       " (1.2867595070730435, 0.396)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predAndLab.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model by computing Mean Squared Error (MSE), which is the average sum of squared differences between predicted and label. \n",
    "\n",
    "This can be computed in a single line using `reduce()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = predAndLab.map(lambda (pred, lab): (pred - lab)**2).reduce(lambda x, y: x + y) / predAndLab.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.762778654801\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2. Repeat (1) with housing_median_age from the original set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+----------+----------+-----------------+-------------------+------------------+\n",
      "|median_house_value_final|total_bedrooms|population|households|    median_income|rooms_per_household|housing_median_age|\n",
      "+------------------------+--------------+----------+----------+-----------------+-------------------+------------------+\n",
      "|                   4.526|         129.0|     322.0|     126.0|           8.3252|  6.984126984126984|              41.0|\n",
      "|                   3.585|        1106.0|    2401.0|    1138.0|           8.3014|  6.238137082601054|              21.0|\n",
      "|                   3.521|         190.0|     496.0|     177.0|7.257399999999999|  8.288135593220339|              52.0|\n",
      "+------------------------+--------------+----------+----------+-----------------+-------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs2 = df_3.select(\"median_house_value_final\", \n",
    "              \"total_bedrooms\", \n",
    "              \"population\", \n",
    "              \"households\", \n",
    "              \"median_income\", \n",
    "              \"rooms_per_household\",\n",
    "                 \"housing_median_age\")\n",
    "dfs2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.526, DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 41.0])),\n",
       " (3.585, DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381, 21.0])),\n",
       " (3.521, DenseVector([190.0, 496.0, 177.0, 7.2574, 8.2881, 52.0]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data2 = dfs2.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "input_data2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|4.526|[129.0,322.0,126....|\n",
      "|3.585|[1106.0,2401.0,11...|\n",
      "|3.521|[190.0,496.0,177....|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for modeling\n",
    "df22 = sqlCtx.createDataFrame(input_data2, [\"label\", \"features\"])\n",
    "df22.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 41.0]), features_scaled=DenseVector([0.3062, 0.2843, 0.3296, 4.3821, 2.8228, 3.2577])),\n",
       " Row(label=3.585, features=DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381, 21.0]), features_scaled=DenseVector([2.6255, 2.1202, 2.9765, 4.3696, 2.5213, 1.6686]))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "standardScaler2 = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the DataFrame to the scaler; this computes the mean, standard deviation of each feature\n",
    "scaler2 = standardScaler2.fit(df22)\n",
    "\n",
    "# Transform the data in `df2` with the scaler\n",
    "scaled_df2 = scaler2.transform(df22)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df2.take(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+------------------+\n",
      "|label|            features|     features_scaled|        prediction|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|0.269|[543.0,1423.0,482...|[1.28902717933820...| 1.604385529626804|\n",
      "|0.329|[386.0,436.0,213....|[0.91632502987945...|1.3133528477522807|\n",
      "|0.396|[296.0,1228.0,289...|[0.70267411617699...|1.2867590563333762|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Mean Squared Error = 0.76277849851\n"
     ]
    }
   ],
   "source": [
    "training2,test2=scaled_df2.randomSplit([0.8,0.2],seed=314)\n",
    "lr2 = LinearRegression(labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel2 = lr2.fit(training2)\n",
    "predicted2=lrModel2.transform(test2)\n",
    "predicted2.show(3)\n",
    "predAndLab2 = predicted2.rdd.map(lambda x: (x.prediction, x.label))\n",
    "predAndLab2.take(3)\n",
    "MSE2 = predAndLab2.map(lambda (pred, lab): (pred - lab)**2).reduce(lambda x, y: x + y) / predAndLab2.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3: Repeat (1) with population_per_household from the original set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+------------------+-----------+--------------+----------+----------+--------+---------+------------------------+-------------------+------------------------+\n",
      "|median_house_value|median_income|housing_median_age|total_rooms|total_bedrooms|population|households|latitude|longitude|median_house_value_final|rooms_per_household|population_per_household|\n",
      "+------------------+-------------+------------------+-----------+--------------+----------+----------+--------+---------+------------------------+-------------------+------------------------+\n",
      "|          452600.0|       8.3252|              41.0|      880.0|         129.0|     322.0|     126.0|   37.88|  -122.23|                   4.526|  6.984126984126984|      2.5555555555555554|\n",
      "|          358500.0|       8.3014|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|   37.86|  -122.22|                   3.585|  6.238137082601054|       2.109841827768014|\n",
      "+------------------+-------------+------------------+-----------+--------------+----------+----------+--------+---------+------------------------+-------------------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_4=df_3.withColumn('population_per_household',df.population/df.households)\n",
    "df_4.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+----------+----------+-----------------+-------------------+------------------------+\n",
      "|median_house_value_final|total_bedrooms|population|households|    median_income|rooms_per_household|population_per_household|\n",
      "+------------------------+--------------+----------+----------+-----------------+-------------------+------------------------+\n",
      "|                   4.526|         129.0|     322.0|     126.0|           8.3252|  6.984126984126984|      2.5555555555555554|\n",
      "|                   3.585|        1106.0|    2401.0|    1138.0|           8.3014|  6.238137082601054|       2.109841827768014|\n",
      "|                   3.521|         190.0|     496.0|     177.0|7.257399999999999|  8.288135593220339|      2.8022598870056497|\n",
      "+------------------------+--------------+----------+----------+-----------------+-------------------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs3 = df_4.select(\"median_house_value_final\", \n",
    "              \"total_bedrooms\", \n",
    "              \"population\", \n",
    "              \"households\", \n",
    "              \"median_income\", \n",
    "              \"rooms_per_household\",\n",
    "                 \"population_per_household\")\n",
    "dfs3.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.526, DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 2.5556])),\n",
       " (3.585, DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381, 2.1098])),\n",
       " (3.521, DenseVector([190.0, 496.0, 177.0, 7.2574, 8.2881, 2.8023]))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data3 = dfs3.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "input_data3.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|4.526|[129.0,322.0,126....|\n",
      "|3.585|[1106.0,2401.0,11...|\n",
      "|3.521|[190.0,496.0,177....|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for modeling\n",
    "df23 = sqlCtx.createDataFrame(input_data3, [\"label\", \"features\"])\n",
    "df23.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 2.5556]), features_scaled=DenseVector([0.3062, 0.2843, 0.3296, 4.3821, 2.8228, 0.2461])),\n",
       " Row(label=3.585, features=DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381, 2.1098]), features_scaled=DenseVector([2.6255, 2.1202, 2.9765, 4.3696, 2.5213, 0.2031]))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "standardScaler3 = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the DataFrame to the scaler; this computes the mean, standard deviation of each feature\n",
    "scaler3 = standardScaler3.fit(df23)\n",
    "\n",
    "# Transform the data in `df2` with the scaler\n",
    "scaled_df3 = scaler3.transform(df23)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df3.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+------------------+\n",
      "|label|            features|     features_scaled|        prediction|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|0.269|[543.0,1423.0,482...|[1.28902717933820...|1.6043858032617577|\n",
      "|0.329|[386.0,436.0,213....|[0.91632502987945...| 1.313353292376104|\n",
      "|0.396|[296.0,1228.0,289...|[0.70267411617699...| 1.286759516581707|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Mean Squared Error = 0.762778658098\n"
     ]
    }
   ],
   "source": [
    "training3,test3=scaled_df3.randomSplit([0.8,0.2],seed=314)\n",
    "lr3 = LinearRegression(labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel3 = lr3.fit(training3)\n",
    "predicted3=lrModel3.transform(test3)\n",
    "predicted3.show(3)\n",
    "predAndLab3 = predicted3.rdd.map(lambda x: (x.prediction, x.label))\n",
    "predAndLab3.take(3)\n",
    "MSE3 = predAndLab3.map(lambda (pred, lab): (pred - lab)**2).reduce(lambda x, y: x + y) / predAndLab3.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part4:  Repeat (1) but do Lasso Regression instead of Linear Regression. hint: change the parameter: regType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,test=scaled_df.randomSplit([0.8,0.2],seed=314)\n",
    "lr4 = LinearRegression(labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+------------------+\n",
      "|label|            features|     features_scaled|        prediction|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|0.269|[543.0,1423.0,482...|[1.28902717933820...|1.6329494455112195|\n",
      "|0.329|[386.0,436.0,213....|[0.91632502987945...|1.3597657687806006|\n",
      "|0.396|[296.0,1228.0,289...|[0.70267411617699...|1.3348029719179593|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Mean Squared Error = 0.780439463658\n"
     ]
    }
   ],
   "source": [
    "lrModel4 = lr4.fit(training)\n",
    "predicted4=lrModel4.transform(test)\n",
    "predicted4.show(3)\n",
    "predAndLab4 = predicted4.rdd.map(lambda x: (x.prediction, x.label))\n",
    "predAndLab4.take(3)\n",
    "MSE4 = predAndLab4.map(lambda (pred, lab): (pred - lab)**2).reduce(lambda x, y: x + y) / predAndLab4.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all RMSE values in a table at bottom, indicating run1, run2, run3, run4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out = pd.DataFrame(columns=['MSE'],index=['run1','run2','run3','run4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.iloc[0]['MSE']=0.762778654801;\n",
    "out.iloc[1]['MSE']=0.76277849851;\n",
    "out.iloc[2]['MSE']=0.762778658098;\n",
    "out.iloc[2]['MSE']=0.780439463658;\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
